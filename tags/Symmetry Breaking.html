<!DOCTYPE HTML>
<html><head><link href="https://use.fontawesome.com/releases/v5.2.0/css/all.css" rel="stylesheet"><link href="https://pwrobinson.github.io/style1.css" rel="stylesheet"><link href="https://pwrobinson.github.io/style2.css" rel="stylesheet"><script type="text/javascript">document.documentElement.className = document.documentElement.className.replace(/no-js/,'js');</script><script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script><script src="jquery.waypoints.min.js"></script><script src="jquery.isonscreen.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}});</script><script type="text/javascript" async="true" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML"></script><script type="text/javascript" src="https://pwrobinson.github.io/script.js"></script><style type="text/css">.MathJax_Preview {color: #888} #MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap} #MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px} .MathJax_Error {color: #CC0000; font-style: italic}</style></head><body><div class="outerContainer"><div id="main"><div id="top_container"><div id="header"><div id="header_container"><div id="address"><h2 id="myname">Peter Robinson</h2><p class="email"><a href="mailto:peter.robinson(at)cityu(dot)edu(dot)hk">peter dot robinson at cityu dot edu dot hk</a></p></div><div id="mypic"><img id="myimg" src="pic.jpg" alt="" width="156" height="204"></div></div><ul id="nav"><li><a class="navLink" id="about" href="#About">About</a></li><li><a class="navLink" id="publications" href="#Publications">Publications</a></li><li><a class="navLink" id="code" href="#Code">Code</a></li><li><a class="navLink" id="teaching" href="#Teaching">Teaching</a></li><li><a class="navLink" id="misc" href="#Misc">Misc</a></li></ul></div></div><div class="mycontainer" class="anchor" id="About"><div class="intro"><p>I&#39;m an Assistant Professor in the Computer Science Department of the City University of Hong Kong. My research focuses on designing new distributed and parallel algorithms, the distributed processing of big data, achieving fault-tolerance in communication networks against adversarial attacks, and developing robust protocols that work in highly dynamic environments such as peer-to-peer Blockchain networks and mobile ad-hoc networks.</p><p>My research has been supported by the General Research Fund (Hong Kong), the Natural Sciences and Engineering Research Council (Canada), IBM Research, and the London Mathematical Society.</p></div><div class="intro"><h2>News</h2><ul id="newsList" class="fa-ul"><li><i class="fa fa-li fa-caret-right"></i>New paper at SODA 2021</li><li><i class="fa fa-li fa-caret-right"></i>General Chair of ACM PODC 2019</li><li><i class="fa fa-li fa-caret-right"></i>On program committee of <a href="http://www.disc-conference.org/wp/">DISC 2021</a>, <a href="https://icdcs2021.us/">ICDCS 2021</a>, <a href="https://sirocco2021.ii.uni.wroc.pl/">SIROCCO 2021</a>, <a href="http://www.podc.org">PODC 2020</a></li></ul></div><div class="tagCloud"><h2 class="tagCloud">Tags <a href="../index.html">(Show all)</a></h2><a class="keyword" style="font-size: 1.5372436em" href="https://pwrobinson.github.io//tags/Asynchrony.html#Publications"> Asynchrony  </a><a class="keyword" style="font-size: 1.2em" href="https://pwrobinson.github.io//tags/Big Data.html#Publications"> Big Data  </a><a class="keyword" style="font-size: 1.2em" href="https://pwrobinson.github.io//tags/Byzantine Failures.html#Publications"> Byzantine Failures  </a><a class="keyword" style="font-size: 1.2em" href="https://pwrobinson.github.io//tags/Churn.html#Publications"> Churn  </a><a class="keyword" style="font-size: 1.2em" href="https://pwrobinson.github.io//tags/Communication Complexity.html#Publications"> Communication Complexity  </a><a class="keyword" style="font-size: 1.8510257em" href="https://pwrobinson.github.io//tags/Distributed Agreement.html#Publications"> Distributed Agreement  </a><a class="keyword" style="font-size: 1.2em" href="https://pwrobinson.github.io//tags/Distributed Storage.html#Publications"> Distributed Storage  </a><a class="keyword" style="font-size: 1.7124022em" href="https://pwrobinson.github.io//tags/Dynamic Network.html#Publications"> Dynamic Network  </a><a class="keyword" style="font-size: 2.0em" href="https://pwrobinson.github.io//tags/Fault-Tolerance.html#Publications"> Fault-Tolerance  </a><a class="keyword" style="font-size: 1.2em" href="https://pwrobinson.github.io//tags/Gossip Communication.html#Publications"> Gossip Communication  </a><a class="keyword" style="font-size: 1.8510257em" href="https://pwrobinson.github.io//tags/Graph Algorithm.html#Publications"> Graph Algorithm  </a><a class="keyword" style="font-size: 1.2em" href="https://pwrobinson.github.io//tags/Haskell.html#Publications"> Haskell  </a><a class="keyword" style="font-size: 1.2em" href="https://pwrobinson.github.io//tags/Information Complexity.html#Publications"> Information Complexity  </a><a class="keyword" style="font-size: 1.5372436em" href="https://pwrobinson.github.io//tags/Leader Election.html#Publications"> Leader Election  </a><a class="keyword" style="font-size: 1.2em" href="https://pwrobinson.github.io//tags/Machine Learning.html#Publications"> Machine Learning  </a><a class="keyword" style="font-size: 1.2em" href="https://pwrobinson.github.io//tags/Mobile Ad-Hoc Network.html#Publications"> Mobile Ad-Hoc Network  </a><a class="keyword" style="font-size: 1.2em" href="https://pwrobinson.github.io//tags/Natural Language Processing.html#Publications"> Natural Language Processing  </a><a class="keyword" style="font-size: 1.4669032em" href="https://pwrobinson.github.io//tags/P2P.html#Publications"> P2P  </a><a class="keyword" style="font-size: 1.6008743em" href="https://pwrobinson.github.io//tags/Secure Computation in Networks.html#Publications"> Secure Computation in Networks  </a><a class="keyword" style="font-size: 1.2em" href="https://pwrobinson.github.io//tags/Self-Healing.html#Publications"> Self-Healing  </a><a class="keyword" style="font-size: 1.3882693em; color:red;" href="https://pwrobinson.github.io//tags/Symmetry Breaking.html#Publications"> Symmetry Breaking  </a><a class="keyword" style="font-size: 1.2em" href="https://pwrobinson.github.io//tags/Wireless Networks.html#Publications"> Wireless Networks  </a></div><h2><a class="anchor" id="Publications">Publications</a></h2><div class="publicationList"><div class="yearContainer"><span class="year">2021</span><ul class="yearList fa-ul"><li class="entry"><i class="fa fa-li fa-caret-right"></i><span class="publicationTitle">Can We Break Symmetry with $o(m)$ Communication?</span><br>Shreyas Pai, Gopal Pandurangan, Sriram V. Pemmaraju, Peter Robinson. <span class="publicationInfo">40th ACM Symposium on Principles of Distributed Computing</span> (<span class="publicationConfShort">PODC 2021</span>). <br></li></ul></div><div class="yearContainer"><span class="year">2018</span><ul class="yearList fa-ul"><li class="entry"><i class="fa fa-li fa-caret-right"></i><span class="publicationTitle">Leader Election in Well-Connected Graphs</span><br>Seth Gilbert, Peter Robinson, Suman Sourav. <span class="publicationInfo">37th ACM Symposium on Principles of Distributed Computing</span> (<span class="publicationConfShort">PODC 2018</span>). <br><a class="abstractToggle invisibleAbstract"><span class="fa fa-plus-square-o">Abstract</span></a><div class="abstract">In this paper, we look at the problem of randomized leader election in synchronous distributed networks with a special focus on the message complexity. We provide an algorithm  that solves the implicit version of leader election (where non-leader nodes  need not be aware of the identity of the leader) in any general network with $O(\sqrt{n} \log^{7/2} n \cdot t_{mix})$ messages and in $O(t_{mix}\log^2 n)$ time, where $n$ is the number of nodes and $t_{mix}$ refers to the mixing time of a random walk in the network graph $G$. For several classes of well-connected networks (that have a large conductance or alternatively small mixing times e.g. expanders, hypercubes, etc), the above result implies extremely efficient (sublinear running time and messages) leader election algorithms. Correspondingly, we show that any substantial improvement is not possible over our algorithm, by presenting an almost matching lower bound for randomized leader election. We show that $\Omega(\sqrt{n}/\phi^{3/4})$ messages are needed for any leader election algorithm that succeeds with probability at least $1-o(1)$, where $\phi$ refers to the conductance of a graph. To the best of our knowledge, this is the first work that shows a dependence between the time and message complexity to solve leader election and the connectivity of the graph $G$, which is often characterized by the graph&#39;s conductance $\phi$. Apart from the $\Omega(m)$ bound in Kutten et al 2015 (where $m$ denotes the number of edges of the graph), this work also provides one of the first non-trivial lower bounds for leader election in general networks.</div></li></ul></div><div class="yearContainer"><span class="year">2017</span><ul class="yearList fa-ul"><li class="entry"><i class="fa fa-li fa-caret-right"></i><span class="publicationTitle">Symmetry Breaking in the Congest Model: Message- and Time-Efficient Algorithms for Ruling Sets.</span><br>Shreyas Pai, Gopal Pandurangan, Sriram V. Pemmaraju, Talal Riaz, Peter Robinson. <span class="publicationInfo">31st International Symposium on Distributed Computing</span> (<span class="publicationConfShort">DISC 2017</span>). <br><a class="abstractToggle invisibleAbstract"><span class="fa fa-plus-square-o">Abstract</span></a><div class="abstract">We study local symmetry breaking problems in the Congest model, focusing on ruling set problems, which generalize the fundamental Maximal Independent Set (MIS) problem. The time (round) complexity of MIS (and ruling sets) have attracted much attention in the Local model. Indeed, recent results (Barenboim et al., FOCS 2012, Ghaffari SODA 2016) for the MIS problem have tried to break the long-standing $O(\log n)$-round ``barrier&#39;&#39; achieved by Luby&#39;s algorithm, but these yield $o(\log n)$-round complexity only when the maximum degree $\Delta$ is somewhat small relative to $n$. More importantly, these results apply only in the Local model.  In fact, the best known time bound in the Congest model is still $O(\log n)$ (via Luby&#39;s algorithm) even for somewhat small $\Delta$.  Furthermore, message complexity has been largely ignored in the context of local symmetry breaking. Luby&#39;s algorithm takes $O(m)$ messages on $m$-edge graphs and this is the best known bound with respect to messages. Our work is motivated by the following central question: can we break the $\Theta(m)$ message bound and the $\Theta(\log n)$ time bound in the Congest model for MIS or closely-related symmetry breaking problems?  This paper presents progress towards this question for the distributed ruling set problem in the Congest model.  A $\beta$-ruling set is an independent set such that every node in the graph is at most $\beta$ hops from a node in the independent set. We present the following results: 1. Time Complexity: We show that we can break the $O(\log n)$ ``barrier&#39;&#39; for 2- and 3-ruling sets.  We compute 3-ruling sets in $O\left(\log n/\log \log n\right)$ rounds with high probability (whp).  More generally we show that 2-ruling sets can be computed in $O\left(\log \Delta \cdot (\log n)^{1/2 + \varepsilon} + \log n/\log\log n\right)$ rounds for any $\varepsilon &gt; 0$, which is $o(\log n)$ for a wide range of $\Delta$ values (e.g., $\Delta = 2^{(\log n)^{1/2-\varepsilon}}$).  These are the first 2- and 3-ruling set algorithms to improve over the $O(\log n)$-round complexity of Luby&#39;s algorithm in the Congest model.  2. Message Complexity:  We show an $\Omega(n^2)$ lower bound on the message complexity of computing an MIS (i.e., 1-ruling set) which holds also for randomized algorithms and present a contrast to this by showing a randomized algorithm for 2-ruling sets that, whp, uses  only $O(n \log^2 n)$ messages and runs in $O(\Delta \log n)$ rounds. This is the first message-efficient algorithm known for ruling sets, which takes near-linear message complexity (which is optimal up to a polylogarithmic factor).  Our results are a step toward understanding the  time and message complexity of symmetry breaking problems in the Congest model.</div></li></ul></div><div class="yearContainer"><span class="year">2016</span><ul class="yearList fa-ul"><li class="entry"><i class="fa fa-li fa-caret-right"></i><span class="publicationTitle">Efficient Computation of Sparse Structures</span><a href="http://onlinelibrary.wiley.com/doi/10.1002/rsa.20653/abstract" target="_new" class="icon"><span class="fa fa-external-link fa-lg">DOI</span></a><br>David G. Harris, Ehab Morsy, Gopal Pandurangan, Peter Robinson, Aravind Srinivasan. <span class="publicationInfo">Random Structures &amp; Algorithms</span> (<span class="publicationConfShort">RSA</span>). <br><a class="abstractToggle invisibleAbstract"><span class="fa fa-plus-square-o">Abstract</span></a><div class="abstract">Basic graph structures such as maximal independent sets (MIS&#39;s)  have spurred much theoretical research in randomized and distributed algorithms, and have several applications in networking and distributed computing as well. However, the extant (distributed) algorithms for these problems do not necessarily guarantee fault-tolerance or load-balance properties. We propose  and study &#39;&#39;low-average degree&#39;&#39; or ``sparse&#39;&#39; versions of such structures. Interestingly, in sharp contrast to, say, MIS&#39;s, it can be shown that checking whether a structure is sparse, will take substantial time. Nevertheless, we are able to develop good  sequential/distributed (randomized) algorithms for such sparse versions.  We also complement our algorithms with several lower bounds. Randomization plays a key role in our upper and lower bound results.</div></li></ul></div><div class="yearContainer"><span class="year">2015</span><ul class="yearList fa-ul"><li class="entry"><i class="fa fa-li fa-caret-right"></i><span class="publicationTitle">On the Complexity of Universal Leader Election</span><a href="https://www.dropbox.com/s/52u4jwftc9l494b/JACM2015.pdf?dl=0" target="_new" class="icon"><span class="fa fa-file-pdf-o fa-lg">PDF</span></a><a href="http://dx.doi.org/10.1145/2699440" target="_new" class="icon"><span class="fa fa-external-link fa-lg">DOI</span></a><br>Shay Kutten, Gopal Pandurangan, David Peleg, Peter Robinson, Amitabh Trehan. <span class="publicationInfo">Journal of the ACM, vol. 62(1), 7:1-7:27</span> (<span class="publicationConfShort">JACM</span>). <br><a class="abstractToggle invisibleAbstract"><span class="fa fa-plus-square-o">Abstract</span></a><div class="abstract">Electing a leader is a fundamental task in distributed computing.  In its implicit version, only the leader must know who is the elected leader.  This paper focuses  on studying the message and time complexity of  randomized implicit leader election  in synchronous  distributed networks. Surprisingly, the most &#39;&#39;obvious&#39;&#39; complexity bounds have not been proven for randomized algorithms. The  ``obvious&#39;&#39; lower bounds of $\Omega(m)$ messages ($m$ is the number of edges in the network) and $\Omega(D)$ time  ($D$ is the network diameter) are non-trivial to show for randomized (Monte Carlo) algorithms. (Recent results that show that even $\Omega(n)$ ($n$ is the number of nodes in the network) is  not a lower bound  on the messages in complete networks, make the above  bounds somewhat less obvious).  To the best of our knowledge, these basic lower bounds have not been established even for deterministic algorithms (except for the limited case of comparison algorithms, where it was also required that some nodes may not wake up spontaneously, and that $D$ and $n$ were not known). We establish these fundamental lower bounds in this paper for the general case, even for randomized Monte Carlo algorithms. Our lower bounds are universal in the sense that they hold for all universal algorithms (such algorithms should work for all graphs), apply to  every $D$, $m$, and $n$, and hold even if $D$, $m$, and $n$ are known, all the nodes wake up simultaneously, and the algorithms can make any use of node&#39;s identities.  To show that these bounds are tight, we present an $O(m)$ messages algorithm. An $O(D)$ time algorithm is known. An interesting fundamental problem is whether both upper bounds (messages and time) can be reached simultaneously in the randomized setting for all graphs. (The answer is known to be negative in the deterministic setting).  We answer this problem partially by presenting a randomized algorithm that matches both complexities in some cases.  This already separates (for some cases) randomized algorithms from deterministic ones.  As first steps towards the general case, we present several universal leader election algorithms with bounds that trade-off messages versus time.  We view our results as a step towards understanding the complexity of universal leader election in distributed networks.</div></li></ul></div><div class="yearContainer"><span class="year">2014</span><ul class="yearList fa-ul"><li class="entry"><i class="fa fa-li fa-caret-right"></i><span class="publicationTitle">Sublinear Bounds for Randomized Leader Election</span><a href="https://www.dropbox.com/s/mrjoq806kww3jo1/TCS2014.pdf?dl=0" target="_new" class="icon"><span class="fa fa-file-pdf-o fa-lg">PDF</span></a><a href="http://dx.doi.org/10.1016/j.tcs.2014.02.009" target="_new" class="icon"><span class="fa fa-external-link fa-lg">DOI</span></a><br>Shay Kutten, Gopal Pandurangan, David Peleg, Peter Robinson, Amitabh Trehan. <span class="publicationInfo">Special Issue of Theoretical Computer Science, Elsevier.</span> (<span class="publicationConfShort">TCS</span>). <br><a class="abstractToggle invisibleAbstract"><span class="fa fa-plus-square-o">Abstract</span></a><div class="abstract">This paper concerns randomized leader election in synchronous distributed networks. A  distributed leader election algorithm  is presented for complete $n$-node networks that  runs in $O(1)$ rounds and (with high probability) uses only $O(\sqrt{n}\log^{3/2} n)$  messages to elect a unique leader (with high probability).  When considering the &#39;&#39;explicit&#39;&#39; variant of leader election where eventually every node knows the identity of the leader, our algorithm yields the asymptotically optimal bounds of $O(1)$ rounds and $O(n)$ messages.  This algorithm is then extended to one solving leader election on any connected non-bipartite $n$-node graph $G$ in $O(\tau(G))$ time and $O(\tau(G)\sqrt{n}\log^{3/2} n)$ messages, where $\tau(G)$ is the mixing time of a random walk on $G$. The above result implies highly efficient (sublinear running time and messages) leader election algorithms for networks with small mixing times, such as expanders and hypercubes.  In contrast, previous  leader election algorithms had at least linear  message complexity even in complete graphs.  Moreover, super-linear message lower bounds are known for time-efficient  deterministic leader election algorithms.  Finally, we present an almost matching lower bound for randomized leader election, showing that $\Omega(\sqrt{n})$ messages are needed for  any leader election algorithm that succeeds with probability at least $1/e + \epsilon$, for any small constant $\epsilon &gt; 0$.  We view our results as a step towards understanding the randomized complexity of leader election in distributed networks. </div></li></ul></div><div class="yearContainer"><span class="year">2013</span><ul class="yearList fa-ul"><li class="entry"><i class="fa fa-li fa-caret-right"></i><span class="publicationTitle">Sublinear Bounds for Randomized Leader Election</span><a href="https://www.dropbox.com/s/ga3wlwlguec5y6e/ICDCN2013.pdf?dl=0" target="_new" class="icon"><span class="fa fa-file-pdf-o fa-lg">PDF</span></a><a href="http://link.springer.com/chapter/10.1007/978-3-642-35668-1_24" target="_new" class="icon"><span class="fa fa-external-link fa-lg">DOI</span></a><br>Shay Kutten, Gopal Pandurangan, David Peleg, Peter Robinson, Amitabh Trehan. <span class="publicationInfo">14th International Conference on Distributed Computing and Networking</span> (<span class="publicationConfShort">ICDCN 2013</span>). <span class="bestPaper">Best Paper Award.</span><br><a class="abstractToggle invisibleAbstract"><span class="fa fa-plus-square-o">Abstract</span></a><div class="abstract">This paper concerns randomized leader election in synchronous distributed networks. A distributed leader election algorithm is presented for complete n-node networks that runs in $O(1)$ rounds and (with high probability) takes only $O(\sqrt{n}\log^{3/2}n)$ messages to elect a unique leader (with high probability). This algorithm is then extended to solve leader election on any connected non-bipartite n-node graph $G$ in $O(\tau(G))$ time and $O(\tau(G)\sqrt{n}\log^{3/2}n)$ messages, where $\tau(G)$ is the mixing time of a random walk on $G$. The above result implies highly efficient (sublinear running time and messages) leader election algorithms for networks with small mixing times, such as expanders and hypercubes. In contrast, previous leader election algorithms had at least linear message complexity even in complete graphs. Moreover, super-linear message lower bounds are known for time-efficient deterministic leader election algorithms. Finally, an almost-tight lower bound is presented for randomized leader election, showing that $\Omega(\sqrt{n})$ messages are needed for any $O(1)$ time leader election algorithm which succeeds with high probability. It is also shown that $\Omega(n^{1/3})$ messages are needed by any leader election algorithm that succeeds with high probability, regardless of the number of the rounds. We view our results as a step towards understanding the randomized complexity of leader election in distributed networks.</div></li><li class="entry"><i class="fa fa-li fa-caret-right"></i><span class="publicationTitle">On the Complexity of Universal Leader Election</span><a href="https://www.dropbox.com/s/za9s6wk37j3nm46/PODC2013-2.pdf?dl=0" target="_new" class="icon"><span class="fa fa-file-pdf-o fa-lg">PDF</span></a><a href="http://doi.acm.org/10.1145/2484239.2484274" target="_new" class="icon"><span class="fa fa-external-link fa-lg">DOI</span></a><br>Shay Kutten, Gopal Pandurangan, David Peleg, Peter Robinson, Amitabh Trehan. <span class="publicationInfo">32nd ACM Symposium on Principles of Distributed Computing</span> (<span class="publicationConfShort">PODC 2013</span>). <br><a class="abstractToggle invisibleAbstract"><span class="fa fa-plus-square-o">Abstract</span></a><div class="abstract">Electing a leader is a fundamental task in distributed computing.  In its implicit version, only the leader must know who is the elected leader.  This paper focuses  on studying the message and time complexity of  randomized implicit leader election  in synchronous  distributed networks. Surprisingly, the most &#39;&#39;obvious&#39;&#39; complexity bounds have not been proven for randomized algorithms. The  ``obvious&#39;&#39; lower bounds of $\Omega(m)$ messages ($m$ is the number of edges in the network) and $\Omega(D)$ time  ($D$ is the network diameter) are non-trivial to show for randomized (Monte Carlo) algorithms. (Recent results that show that even $\Omega(n)$ ($n$ is the number of nodes in the network) is  not a lower bound  on the messages in complete networks, make the above  bounds somewhat less obvious).  To the best of our knowledge, these basic lower bounds have not been established even for deterministic algorithms (except for the limited case of comparison algorithms, where it was also required that some nodes may not wake up spontaneously, and that $D$ and $n$ were not known). We establish these fundamental lower bounds in this paper for the general case, even for randomized Monte Carlo algorithms. Our lower bounds are universal in the sense that they hold for all universal algorithms (such algorithms should work for all graphs), apply to  every $D$, $m$, and $n$, and hold even if $D$, $m$, and $n$ are known, all the nodes wake up simultaneously, and the algorithms can make any use of node&#39;s identities.  To show that these bounds are tight, we present an $O(m)$ messages algorithm. An $O(D)$ time algorithm is known. An interesting fundamental problem is whether  both upper bounds (messages and time) can be reached simultaneously in the randomized setting for all graphs. (The answer is known to be negative in the deterministic setting).  We answer this problem partially by presenting a randomized algorithm that matches both complexities in some cases.  This already separates (for some cases) randomized algorithms from deterministic ones.  As first steps towards the general case, we present several universal leader election algorithms with bounds that trade-off messages versus time.  We view our results as a step towards understanding the complexity of universal leader election in distributed networks.</div></li></ul></div></div><div class="intro revealOnScroll"><h2><a class="anchor" id="Code">Code</a></h2><div>I&#39;m interested in parallel and distributed programming and related technologies such as software transactional memory and the actor-model. Recently, I have been working on implementing a simulation environment for distributed algorithms in Elixir/Erlang, and implementing non-blocking data structures in Haskell suitable for multi-core machines. Below is a (non-comprehensive) list of software that I have written. </div><ul class="longList fa-ul"><li><i class="fa fa-li fa-caret-right"></i><a class="external" href="http://hackage.haskell.org/package/concurrent-hashtable">concurrent hash table:</a> a thread-safe hash table that scales to multicores.</li><li><i class="fa fa-li fa-caret-right"></i><a class="external" href="http://hackage.haskell.org/package/data-dispersal">data dispersal:</a> an implementation of an (m,n)-threshold information dispersal scheme that is space-optimal.</li><li><i class="fa fa-li fa-caret-right"></i><a class="external" href="http://hackage.haskell.org/package/secret-sharing">secret sharing:</a> an implementation of a secret sharing scheme that provides information-theoretic security.</li><li><i class="fa fa-li fa-caret-right"></i><a class="external" href="http://hackage.haskell.org/package/tskiplist">tskiplist:</a> a data structure with range-query support for software transactional memory.</li><li><i class="fa fa-li fa-caret-right"></i><a class="external" href="http://hackage.haskell.org/package/stm-io-hooks">stm-io-hooks:</a> An extension of Haskell&#39;s Software Transactional Memory (STM) monad with commit and retry IO hooks.</li><li><i class="fa fa-li fa-caret-right"></i><a class="external" href="http://hackage.haskell.org/package/mathgenealogy">Mathgenealogy:</a> Visualize your (academic) genealogy! A program for extracting data from the Mathematics Genealogy project.</li><li><i class="fa fa-li fa-caret-right"></i>I extended Haskell&#39;s <a class="external" href="https://www.haskell.org/cabal/">Cabal,</a> for using a &quot;world&quot; file to keep track of installed packages.  (Now part of the main distribution.)</li></ul></div><div class="intro revealOnScroll" id="teaching"><h2><a class="anchor" id="Teaching">Teaching</a></h2><ul class="longList fa-ul"><li><i class="fa fa-li fa-caret-right"></i>Computer Networks, Fall 2020, 2019.</li><li><i class="fa fa-li fa-caret-right"></i>Database Systems, Spring 2020.</li><li><i class="fa fa-li fa-caret-right"></i>Distributed Computing, Spring 2019.</li><li><i class="fa fa-li fa-caret-right"></i>Randomized Algorithms, Fall 2018: <a class="external" href="https://www.cas.mcmaster.ca/robinson/teaching/cas781/intro_slides/">Intro slides. </a><a class="external" href="https://www.cas.mcmaster.ca/robinson/teaching/cas781/markov/">Part 1 on Concentration Bounds.</a></li><li><i class="fa fa-li fa-caret-right"></i>Advanced Distributed Systems, Fall 2016, 2017.</li><li><i class="fa fa-li fa-caret-right"></i>Computation with Data, Fall 2016.</li><li><i class="fa fa-li fa-caret-right"></i>Internet and Web Technologies, Spring 2016.</li></ul></div><div class="intro revealOnScroll" id="misc"><h2><a class="anchor" id="Misc">Misc</a></h2><ul class="longList fa-ul"><li><i class="fa fa-li fa-caret-right"></i>Google scholar <a class="external" href="http://scholar.google.com/citations?user=DsPjnMQAAAAJ&amp;hl=en">profile</a></li><li><i class="fa fa-li fa-caret-right"></i>My profile on <a class="external" href="http://stackexchange.com/users/555378/monoid">StackExchange</a></li></ul></div></div></div></div></body></html>